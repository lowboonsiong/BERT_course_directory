{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8503428",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 09:42:48.444431: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-02 09:42:48.465784: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-12-02 09:42:48.638647: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-12-02 09:42:48.787956: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1764639768.913838    1137 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1764639768.951542    1137 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1764639769.236652    1137 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1764639769.236728    1137 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1764639769.236731    1137 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1764639769.236733    1137 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-12-02 09:42:49.273342: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/lowboonsiong/projects/bert_venv/lib/python3.12/site-packages/tensorflow_hub/__init__.py:61: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import parse_version\n",
      "/home/lowboonsiong/projects/bert_venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.19.1\n",
      "KerasNLP Version: 0.23.0\n",
      "Python Version: 3.12.3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow import keras\n",
    "import keras_nlp\n",
    "import platform\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "print(f\"TensorFlow Version: {tf.__version__}\")\n",
    "print(f\"KerasNLP Version: {keras_nlp.__version__}\")\n",
    "print(f\"Python Version: {platform.python_version()}\")\n",
    "\n",
    "# Recommended: TensorFlow >= 2.15, KerasNLP >= 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b5afe5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU detected. cuDNN is not being used.\n"
     ]
    }
   ],
   "source": [
    "# Check for GPU devices\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(\"GPU Detected:\", gpus)\n",
    "    # If the GPU is detected and TensorFlow is configured correctly,\n",
    "    # cuDNN is almost certainly working and enabled.\n",
    "    print(\"cuDNN status: Inferred as ENABLED and operational.\")\n",
    "else:\n",
    "    print(\"No GPU detected. cuDNN is not being used.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d90ef2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coursetitle</th>\n",
       "      <th>trainingprovideralias</th>\n",
       "      <th>ihl_status</th>\n",
       "      <th>courseratings_stars</th>\n",
       "      <th>jobcareer_impact_stars</th>\n",
       "      <th>full_course_fee</th>\n",
       "      <th>course_fee_after_subsidies</th>\n",
       "      <th>number_of_hours</th>\n",
       "      <th>training_commitment</th>\n",
       "      <th>about_this_course</th>\n",
       "      <th>what_you_learn</th>\n",
       "      <th>attendancecount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14319</th>\n",
       "      <td>Professional, Legal and Ethical Healthcare Pra...</td>\n",
       "      <td>HMI INSTITUTE OF HEALTH SCIENCES PTE. LTD.</td>\n",
       "      <td>NON-IHL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>902.0</td>\n",
       "      <td>451.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Enable learner to apply organisational code of...</td>\n",
       "      <td>Learning unit 1: Concept of accountability as ...</td>\n",
       "      <td>143.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12041</th>\n",
       "      <td>Principles of Management (in MC in Business Fu...</td>\n",
       "      <td>Temasek Polytechnic</td>\n",
       "      <td>IHL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1698.0</td>\n",
       "      <td>1698.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>Part Time</td>\n",
       "      <td>If you attend this course, you will be equippe...</td>\n",
       "      <td>This subject covers the key management functio...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             coursetitle  \\\n",
       "14319  Professional, Legal and Ethical Healthcare Pra...   \n",
       "12041  Principles of Management (in MC in Business Fu...   \n",
       "\n",
       "                            trainingprovideralias ihl_status  \\\n",
       "14319  HMI INSTITUTE OF HEALTH SCIENCES PTE. LTD.    NON-IHL   \n",
       "12041                         Temasek Polytechnic        IHL   \n",
       "\n",
       "       courseratings_stars  jobcareer_impact_stars  full_course_fee  \\\n",
       "14319                  0.0                     0.0            902.0   \n",
       "12041                  0.0                     0.0           1698.0   \n",
       "\n",
       "       course_fee_after_subsidies  number_of_hours training_commitment  \\\n",
       "14319                       451.0             41.0           Full Time   \n",
       "12041                      1698.0             60.0           Part Time   \n",
       "\n",
       "                                       about_this_course  \\\n",
       "14319  Enable learner to apply organisational code of...   \n",
       "12041  If you attend this course, you will be equippe...   \n",
       "\n",
       "                                          what_you_learn  attendancecount  \n",
       "14319  Learning unit 1: Concept of accountability as ...            143.0  \n",
       "12041  This subject covers the key management functio...              0.0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/csv_training/training_course_directory.csv')\n",
    "df.sample(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "db3f6bf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['coursetitle',\n",
       " 'trainingprovideralias',\n",
       " 'ihl_status',\n",
       " 'courseratings_stars',\n",
       " 'jobcareer_impact_stars',\n",
       " 'full_course_fee',\n",
       " 'course_fee_after_subsidies',\n",
       " 'number_of_hours',\n",
       " 'training_commitment',\n",
       " 'about_this_course',\n",
       " 'what_you_learn',\n",
       " 'attendancecount']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8ae07a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Input Text:\n",
      "TITLE: Java Programming for Complete Beginners(Classroom and Synchronous e-learning). SCHOOL: NON-IHL. COURSE RATING: 4.0. JOB RATING: 0.0. FEE: $1400.0. FEE AFTER SUBSIDIES: $ 420.0. TRAINING HOUR: 28.0 hours. TRAINING COMMITMENT: Part Time. DESCRIPTIONS: LO1: Gather and confi rm the architecture requirements_x000D_LO2: Derive high-level design from specifi cation_x000D_LO3: Apply Java language syntax and layout_x000D_LO4: Apply basic object-oriented interaction principles_x000D_LO5: Document the design. SKILLS: Object-oriented design is a process by which a set of detailed object-oriented software design models are built, which are then used by the programmers to write and test programs for the new system. Systems design is the bridge between user requirements and programming the new system. One strength of the object-oriented approach is that the design models are often an extension of the requirements models. Object-oriented design is an analytical, rigorous, and detailed process and Java programming language is the selected programming language to implement such design into programs for the new system.\n",
      "Sample Target Value (Original): 12.0\n",
      "Sample Target Value (Scaled): [-0.17442319]\n"
     ]
    }
   ],
   "source": [
    "# Combine all descriptive columns (A-E) into a single text feature\n",
    "# This embeds the structured data (Rating, Fee, etc.) directly into the text for BERT\n",
    "df['Full_Text'] = (\n",
    "    \"TITLE: \" + df['coursetitle'].astype(str) + \". \" +\n",
    "    \"SCHOOL: \" + df['ihl_status'].astype(str) + \". \" +\n",
    "    \"COURSE RATING: \" + df['courseratings_stars'].astype(str) + \". \" +\n",
    "    \"JOB RATING: \" + df['jobcareer_impact_stars'].astype(str) + \". \" +\n",
    "    \"FEE: $\" + df['full_course_fee'].astype(str) + \". \" +\n",
    "    \"FEE AFTER SUBSIDIES: $ \" + df['course_fee_after_subsidies'].astype(str) + \". \" +\n",
    "    \"TRAINING HOUR: \" + df['number_of_hours'].astype(str) + \" hours. \" +\n",
    "    \"TRAINING COMMITMENT: \" + df['training_commitment'].astype(str) + \". \" +\n",
    "    \"DESCRIPTIONS: \" + df['about_this_course'].astype(str) + \". \" +   \n",
    "    \"SKILLS: \" + df['what_you_learn'].astype(str)\n",
    ")\n",
    "\n",
    "X = df['Full_Text'].values\n",
    "y = df['attendancecount'].values\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Important: Scale the target variable (y) for better regression performance\n",
    "scaler = StandardScaler()\n",
    "y_train_scaled = scaler.fit_transform(y_train.reshape(-1, 1))\n",
    "y_test_scaled = scaler.transform(y_test.reshape(-1, 1))\n",
    "\n",
    "print(f\"Sample Input Text:\\n{X_train[0]}\")\n",
    "print(f\"Sample Target Value (Original): {y_train[0]}\")\n",
    "print(f\"Sample Target Value (Scaled): {y_train_scaled[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "63aea8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"bert_text_classifier_preprocessor\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mPreprocessor: \"bert_text_classifier_preprocessor\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                                                  </span>â”ƒ<span style=\"font-weight: bold\">                                   Config </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ bert_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BertTokenizer</span>)                                â”‚                       Vocab size: <span style=\"color: #00af00; text-decoration-color: #00af00\">30,522</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                                                 \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m                                  Config\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ bert_tokenizer (\u001b[38;5;33mBertTokenizer\u001b[0m)                                â”‚                       Vocab size: \u001b[38;5;34m30,522\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"bert_text_classifier\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"bert_text_classifier\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                  </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape              </span>â”ƒ<span style=\"font-weight: bold\">         Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to               </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                          â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ segment_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                          â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                          â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ bert_backbone (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BertBackbone</span>)  â”‚ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">4,385,920</span> â”‚ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        â”‚\n",
       "â”‚                               â”‚ <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)]               â”‚                 â”‚ segment_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         â”‚\n",
       "â”‚                               â”‚                           â”‚                 â”‚ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ classifier_dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ bert_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ logits (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> â”‚ classifier_dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              â”‚               \u001b[38;5;34m0\u001b[0m â”‚ -                          â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ segment_ids (\u001b[38;5;33mInputLayer\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              â”‚               \u001b[38;5;34m0\u001b[0m â”‚ -                          â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              â”‚               \u001b[38;5;34m0\u001b[0m â”‚ -                          â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ bert_backbone (\u001b[38;5;33mBertBackbone\u001b[0m)  â”‚ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      â”‚       \u001b[38;5;34m4,385,920\u001b[0m â”‚ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        â”‚\n",
       "â”‚                               â”‚ \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)]               â”‚                 â”‚ segment_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         â”‚\n",
       "â”‚                               â”‚                           â”‚                 â”‚ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ classifier_dropout (\u001b[38;5;33mDropout\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               â”‚               \u001b[38;5;34m0\u001b[0m â”‚ bert_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ logits (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 â”‚             \u001b[38;5;34m129\u001b[0m â”‚ classifier_dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,386,049</span> (16.73 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,386,049\u001b[0m (16.73 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,386,049</span> (16.73 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,386,049\u001b[0m (16.73 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def build_keras_nlp_regression_model():\n",
    "    # Use the BertClassifier Task Model for simpler setup\n",
    "    # num_classes=1 gives us one output neuron\n",
    "    # change from bert_base_en_uncased (110million params) to smaller model\n",
    "    # keras_nlp.models.BertClassifier.from_preset() will insert [CLS] and [SEP] tokens automatically\n",
    "    # bert_small_en_uncased (29 million params), bert_mini_en_uncased (14million params) or bert_tiny_en_uncased(4.4million params)\n",
    "    model = keras_nlp.models.BertClassifier.from_preset(\n",
    "        \"bert_tiny_en_uncased\",\n",
    "        num_classes=1, \n",
    "        load_weights=True,\n",
    "        # Set max sequence length based on your average text length\n",
    "        # Change from 128 to 64 as WSL keep crashing during training\n",
    "        preprocessor_config={\"sequence_length\": 128} \n",
    "    )\n",
    "    \n",
    "    # Critical modification: change the final layer's activation from softmax/sigmoid to linear\n",
    "    # This converts the model from classification to regression.\n",
    "    model.layers[-1].activation = tf.keras.activations.linear\n",
    "    \n",
    "    # Compile for Regression\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=3e-5), # Low learning rate for fine-tuning\n",
    "        loss=tf.keras.losses.MeanSquaredError(), # MSE loss for regression\n",
    "        metrics=[tf.keras.metrics.MeanAbsoluteError(name='mae')]\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "regression_model = build_keras_nlp_regression_model()\n",
    "print(\"\\nModel Summary:\")\n",
    "regression_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba5db4bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating token lengths...\n",
      "\n",
      "--- Token Length Analysis Summary ---\n",
      "BERT Preset Used: bert_tiny_en_uncased\n",
      "Max Sequence Length in Model: 128\n",
      "----------------------------------------\n",
      "Total Training Samples: 20650\n",
      "Average Token Length: 296.29 tokens\n",
      "Maximum Token Length: 1426 tokens\n",
      "Minimum Token Length: 66 tokens\n",
      "----------------------------------------\n",
      "Samples Exceeding 128 Tokens (Truncated): 19580 samples\n",
      "Percentage of Truncated Samples: 94.82%\n",
      "----------------------------------------\n",
      "Length of Longest Sample: 1426\n",
      "Length of Shortest Sample: 66\n"
     ]
    }
   ],
   "source": [
    "# --- Configuration ---\n",
    "PRESET = \"bert_tiny_en_uncased\"\n",
    "MAX_SEQUENCE_LENGTH = 128 # Your limit\n",
    "\n",
    "# --- 1. Load the Tokenizer ---\n",
    "# We use the raw tokenizer to see the length BEFORE padding/truncation\n",
    "tokenizer = keras_nlp.models.BertTokenizer.from_preset(\n",
    "    PRESET\n",
    ")\n",
    "\n",
    "# --- 2. Define a function to calculate token length ---\n",
    "# This function calculates the number of tokens for a given text,\n",
    "# *including* the automatically added [CLS] and [SEP] tokens.\n",
    "def get_token_length(text):\n",
    "    # Tokenize the text.\n",
    "    token_ids = tokenizer.tokenize(text)\n",
    "    # The length of the resulting tensor is the number of tokens\n",
    "    return tf.shape(token_ids)[0].numpy()\n",
    "\n",
    "# --- 3. Apply the function to your full dataset (X_train) ---\n",
    "print(\"Calculating token lengths...\")\n",
    "# Use list comprehension for efficient processing\n",
    "token_lengths = [get_token_length(text) for text in X_train]\n",
    "\n",
    "# Convert to a numpy array for easy statistical calculation\n",
    "token_lengths = np.array(token_lengths)\n",
    "\n",
    "# --- 4. Analyze Results ---\n",
    "\n",
    "# Calculate statistics\n",
    "avg_length = np.mean(token_lengths)\n",
    "max_length = np.max(token_lengths)\n",
    "min_length = np.min(token_lengths)\n",
    "\n",
    "# Calculate truncation metrics\n",
    "# An input is truncated if its length is greater than the MAX_SEQUENCE_LENGTH\n",
    "truncated_count = np.sum(token_lengths > MAX_SEQUENCE_LENGTH)\n",
    "total_samples = len(X_train)\n",
    "percent_truncated = (truncated_count / total_samples) * 100\n",
    "\n",
    "# --- 5. Print Summary ---\n",
    "print(\"\\n--- Token Length Analysis Summary ---\")\n",
    "print(f\"BERT Preset Used: {PRESET}\")\n",
    "print(f\"Max Sequence Length in Model: {MAX_SEQUENCE_LENGTH}\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"Total Training Samples: {total_samples}\")\n",
    "print(f\"Average Token Length: {avg_length:.2f} tokens\")\n",
    "print(f\"Maximum Token Length: {max_length} tokens\")\n",
    "print(f\"Minimum Token Length: {min_length} tokens\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"Samples Exceeding {MAX_SEQUENCE_LENGTH} Tokens (Truncated): {truncated_count} samples\")\n",
    "print(f\"Percentage of Truncated Samples: {percent_truncated:.2f}%\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Example of a long and short text's length\n",
    "long_sample_index = np.argmax(token_lengths)\n",
    "short_sample_index = np.argmin(token_lengths)\n",
    "\n",
    "print(f\"Length of Longest Sample: {token_lengths[long_sample_index]}\")\n",
    "print(f\"Length of Shortest Sample: {token_lengths[short_sample_index]}\")\n",
    "\n",
    "# Note: The calculation above includes the [CLS] and [SEP] tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d89064c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m5163/5163\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m446s\u001b[0m 86ms/step - loss: 0.9175 - mae: 0.2478 - val_loss: 0.7531 - val_mae: 0.2040\n",
      "Epoch 2/3\n",
      "\u001b[1m5163/5163\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m444s\u001b[0m 86ms/step - loss: 0.8399 - mae: 0.2306 - val_loss: 0.7392 - val_mae: 0.2279\n",
      "Epoch 2: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m162/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 136ms/step\n",
      "\n",
      "--- Sample Predictions (Test Set) ---\n",
      "      Actual_Students  Predicted_Students\n",
      "0                 0.0                16.0\n",
      "1                 0.0                12.0\n",
      "2              1371.0               797.0\n",
      "3               436.0               176.0\n",
      "4                32.0                70.0\n",
      "...               ...                 ...\n",
      "5158             27.0               143.0\n",
      "5159              5.0                10.0\n",
      "5160             22.0               338.0\n",
      "5161             13.0                45.0\n",
      "5162              0.0                17.0\n",
      "\n",
      "[5163 rows x 2 columns]\n",
      "\n",
      "Final Mean Absolute Error (Unscaled): 149.14 students\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_mae', \n",
    "    patience=1, \n",
    "    restore_best_weights=True,\n",
    "    verbose=1 \n",
    ")\n",
    "\n",
    "history = regression_model.fit(\n",
    "    x=X_train,\n",
    "    y=y_train_scaled,\n",
    "    validation_data=(X_test, y_test_scaled),\n",
    "    epochs=3,\n",
    "    batch_size=4, #change from 16 to 4 as WSL keep crashing during training\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Make predictions on the test set (results are scaled)\n",
    "y_pred_scaled = regression_model.predict(X_test)\n",
    "\n",
    "# Inverse transform the predictions to the original student count scale\n",
    "\n",
    "y_pred = scaler.inverse_transform(y_pred_scaled)\n",
    "\n",
    "# Display results\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual_Students': y_test,\n",
    "    'Predicted_Students': y_pred.flatten().round(0) # Round to nearest whole number\n",
    "})\n",
    "\n",
    "print(\"\\n--- Sample Predictions (Test Set) ---\")\n",
    "print(results_df)\n",
    "\n",
    "# Calculate final unscaled MAE\n",
    "final_mae = np.mean(np.abs(results_df['Actual_Students'] - results_df['Predicted_Students']))\n",
    "print(f\"\\nFinal Mean Absolute Error (Unscaled): {final_mae:.2f} students\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1cc7fa8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: 0.1608\n",
      "Mean Absolute Error (MAE): 149.1388\n",
      "Mean Squared Error (MSE): 402566.8642\n"
     ]
    }
   ],
   "source": [
    "# R2 Score (Coefficient of Determination)\n",
    "# Best value is 1.0. Can be negative.\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"R2 Score: {r2:.4f}\")\n",
    "\n",
    "# Mean Absolute Error (MAE)\n",
    "# Measures the average magnitude of the errors in a set of predictions.\n",
    "# Best value is 0.0.\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "\n",
    "# Mean Squared Error (MSE)\n",
    "# Measures the average of the squares of the errors. Penalizes larger errors more.\n",
    "# Best value is 0.0.\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error (MSE): {mse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c86bb36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model saved successfully to: data/model/bert_regression_model.keras\n"
     ]
    }
   ],
   "source": [
    "#Save the BERT mode.\n",
    "# MODEL_SAVE_PATH = 'data/model/bert_regression_model.keras'\n",
    "# regression_model.save(MODEL_SAVE_PATH) \n",
    "# print(f\"\\nModel saved successfully to: {MODEL_SAVE_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0adf0b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaler successfully saved as 'data/model/bert_model_scaler.pkl'\n"
     ]
    }
   ],
   "source": [
    "# #Save the Fitted Scaler ---\n",
    "# scaler_filename = 'data/model/bert_model_scaler.pkl'\n",
    "\n",
    "# try:\n",
    "#     with open(scaler_filename, 'wb') as file:\n",
    "#         # Save the fitted scaler object\n",
    "#         pickle.dump(scaler, file)\n",
    "#     print(f\"Scaler successfully saved as '{scaler_filename}'\")\n",
    "# except Exception as e:\n",
    "#     print(f\"Error saving scaler: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27903d59",
   "metadata": {},
   "source": [
    "<h3>Load the model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36b76921",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1764639785.558263    1137 cuda_executor.cc:1228] INTERNAL: CUDA Runtime error: Failed call to cudaGetRuntimeVersion: Error loading CUDA libraries. GPU will not be used.: Error loading CUDA libraries. GPU will not be used.\n",
      "W0000 00:00:1764639785.560124    1137 gpu_device.cc:2341] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "/home/lowboonsiong/projects/bert_venv/lib/python3.12/site-packages/keras/src/saving/serialization_lib.py:749: UserWarning: `compile()` was not called as part of model loading because the model's `compile()` method is custom. All subclassed Models that have `compile()` overridden should also override `get_compile_config()` and `compile_from_config(config)`. Alternatively, you can call `compile()` manually after loading.\n",
      "  instance.compile_from_config(compile_config)\n",
      "/home/lowboonsiong/projects/bert_venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:797: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 84 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "#Load BERT MODEL\n",
    "model_path = 'data/model/bert_regression_model.keras' \n",
    "loaded_model = keras.models.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d69de9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaler successfully loaded from 'data/model/bert_model_scaler.pkl'\n",
      "Loaded Scaler Mean: 139.53\n",
      "Loaded Scaler Std Dev: 731.14\n"
     ]
    }
   ],
   "source": [
    "#Load Scaler pickle model ---\n",
    "scaler_filename = 'data/model/bert_model_scaler.pkl'\n",
    "\n",
    "try:\n",
    "    with open(scaler_filename, 'rb') as file:\n",
    "        # Load the fitted scaler object\n",
    "        loaded_scaler = pickle.load(file)\n",
    "    print(f\"Scaler successfully loaded from '{scaler_filename}'\")\n",
    "\n",
    "    # Verify that the loaded scaler has the correct values\n",
    "    print(f\"Loaded Scaler Mean: {loaded_scaler.mean_[0]:.2f}\")\n",
    "    print(f\"Loaded Scaler Std Dev: {loaded_scaler.scale_[0]:.2f}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Scaler file '{scaler_filename}' not found.\")\n",
    "    loaded_scaler = None\n",
    "except Exception as e:\n",
    "    print(f\"Error loading scaler: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02504820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 557ms/step\n",
      "\n",
      "--- NEW COURSE PREDICTION ---\n",
      "Predicted Number of Students to Attend: **612**\n"
     ]
    }
   ],
   "source": [
    "def predict_new_course_students(model, scaler, course_data):\n",
    "    #Remeber to change the key to new one after testing the first model\n",
    "    new_input_text = (\n",
    "        \"TITLE: \" + str(course_data['coursetitle']) + \". \" +\n",
    "        \"SCHOOL: \" + str(course_data['ihl_status']) + \". \" +\n",
    "        \"COURSE RATING: \" + str(course_data['courseratings_stars']) + \". \" +\n",
    "        \"JOB RATING: \" + str(course_data['jobcareer_impact_stars']) + \". \" +\n",
    "        \"FEE: $\" + str(course_data['full_course_fee']) + \". \" +\n",
    "        \"FEE AFTER SUBSIDIES (IF ANY): $ \" + str(course_data['course_fee_after_subsidies']) + \". \" +\n",
    "        \"TRAINING HOUR: \" + str(course_data['number_of_hours']) + \". \" +\n",
    "        \"TRAINING COMMITMENT: \" + str(course_data['training_commitment']) + \". \" +\n",
    "        \"DESCRIPTIONS: \" + str(course_data['about_this_course']) + \". \" + \n",
    "        \"SKILLS: \" + str(course_data['what_you_learn'])\n",
    "    )\n",
    "\n",
    "    # Convert the single string into a NumPy array of strings for the model\n",
    "    X_new = np.array([new_input_text])    \n",
    "    y_pred_scaled = model.predict(X_new)\n",
    "    \n",
    "    # Inverse Transform and Finalize ---\n",
    "    # Convert scaled value back to original student count\n",
    "    y_pred = scaler.inverse_transform(y_pred_scaled)\n",
    "    \n",
    "    # Round to the nearest whole number and ensure it's not negative\n",
    "    predicted_students = max(0, int(round(y_pred[0][0])))\n",
    "    \n",
    "    return predicted_students, new_input_text\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "## ğŸ¯ Define the New Course Data\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Define the features for a hypothetical new course\n",
    "new_course_features = {\n",
    "    'coursetitle': \"Engineering Ethics\",\n",
    "    'ihl_status': \"IHL\",\n",
    "    'courseratings_stars': 0.0,\n",
    "    'jobcareer_impact_stars': 0.0,\n",
    "    'full_course_fee': 1461.0,\n",
    "    'course_fee_after_subsidies': 438.30,\n",
    "    'number_of_hours': 36,\n",
    "    'training_commitment': \"Full Time\",\n",
    "    'about_this_course': \"Nowadays, technology has a pervasive and profound impact on everyday life, where engineers play a crucial role in its development. It is therefore extremely important that engineers understand the importance of safety, health, and welfare of the public, when developing this technology. They must be morally committed and equipped to tackle any ethical issues they may encounter. This course aims at training the student to reach such a status through discussions and typical case studies where real examples are thoroughly discussed.\",\n",
    "    'what_you_learn': \"Ethics and Professionalism. Moral Choices and Ethical Dilemmas. Codes of Ethics. Moral Frameworks. Ethics as Social Experimentation. Safety and Risk. Assessing and Reducing Risk. Workplace Responsibilities and Rights. Truth and Truthfulness. Computer Ethics. Environmental Ethics;\"\n",
    "}\n",
    "\n",
    "new_course_features2 = {\n",
    "    #'coursetitle': \"Public Areas Housekeeping Operations Management - L1 (Classroom)\",\n",
    "    'coursetitle': \"Washing and Cleaning of Public Toilets, Showers and Change Rooms\",\n",
    "    'ihl_status': \"IHL\",\n",
    "    'courseratings_stars': 3.0,\n",
    "    'jobcareer_impact_stars': 3.0,\n",
    "    'full_course_fee': 400.0,\n",
    "    'course_fee_after_subsidies': 100.00,\n",
    "    'number_of_hours': 16,\n",
    "    'training_commitment': \"Full Time\",\n",
    "    # 'about_this_course': \"Nothing\",\n",
    "    # 'what_you_learn': \"Nothing\"\n",
    "    'about_this_course': \"Learner will have knowledge and application skills in public toilets washing and cleaning, showers and change rooms and be able to apply them to the workplace\",\n",
    "    'what_you_learn': \"1. Following procedures for starting and ending shift. 2. following procedures for servicing and washing toilets, showers and change rooms 3. cleaning surfaces in toilets, showers and change rooms\"\n",
    "}\n",
    "\n",
    "# --- Execute the Prediction ---\n",
    "if loaded_model:\n",
    "    predicted_count, input_text = predict_new_course_students(loaded_model, loaded_scaler, new_course_features2)\n",
    "\n",
    "    print(\"\\n--- NEW COURSE PREDICTION ---\")\n",
    "    print(f\"Predicted Number of Students to Attend: **{predicted_count}**\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bert_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
