{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8503428",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 12:36:39.045002: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-27 12:36:39.062461: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-27 12:36:39.178022: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-27 12:36:39.273566: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1764218199.342076    2203 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1764218199.360895    2203 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1764218199.548533    2203 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1764218199.548572    2203 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1764218199.548574    2203 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1764218199.548575    2203 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-11-27 12:36:39.572536: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/lowboonsiong/projects/bert_venv/lib/python3.12/site-packages/tensorflow_hub/__init__.py:61: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import parse_version\n",
      "/home/lowboonsiong/projects/bert_venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.19.1\n",
      "KerasNLP Version: 0.23.0\n",
      "Python Version: 3.12.3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow import keras\n",
    "import keras_nlp\n",
    "import platform\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "print(f\"TensorFlow Version: {tf.__version__}\")\n",
    "print(f\"KerasNLP Version: {keras_nlp.__version__}\")\n",
    "print(f\"Python Version: {platform.python_version()}\")\n",
    "\n",
    "# Recommended: TensorFlow >= 2.15, KerasNLP >= 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b5afe5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Detected: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "cuDNN status: Inferred as ENABLED and operational.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1764169238.844279     811 gpu_device.cc:2430] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 12.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.\n"
     ]
    }
   ],
   "source": [
    "# Check for GPU devices\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(\"GPU Detected:\", gpus)\n",
    "    # If the GPU is detected and TensorFlow is configured correctly,\n",
    "    # cuDNN is almost certainly working and enabled.\n",
    "    print(\"cuDNN status: Inferred as ENABLED and operational.\")\n",
    "else:\n",
    "    print(\"No GPU detected. cuDNN is not being used.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d90ef2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coursetitle</th>\n",
       "      <th>trainingprovideralias</th>\n",
       "      <th>ihl_status</th>\n",
       "      <th>courseratings_stars</th>\n",
       "      <th>jobcareer_impact_stars</th>\n",
       "      <th>full_course_fee</th>\n",
       "      <th>course_fee_after_subsidies</th>\n",
       "      <th>number_of_hours</th>\n",
       "      <th>training_commitment</th>\n",
       "      <th>about_this_course</th>\n",
       "      <th>what_you_learn</th>\n",
       "      <th>attendancecount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20277</th>\n",
       "      <td>Advanced Certificate in Supply Chain Intellige...</td>\n",
       "      <td>SINGAPORE MANAGEMENT UNIVERSITY</td>\n",
       "      <td>IHL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Analysing the supply chain is of paramount imp...</td>\n",
       "      <td>At the end of the 3-day module, participants w...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12321</th>\n",
       "      <td>Network Analysis and Forensics</td>\n",
       "      <td>Singapore Polytechnic</td>\n",
       "      <td>IHL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1824.0</td>\n",
       "      <td>1824.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>Part Time</td>\n",
       "      <td>This course aims to equip diploma (and above) ...</td>\n",
       "      <td>The course introduces students with the fundam...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             coursetitle  \\\n",
       "20277  Advanced Certificate in Supply Chain Intellige...   \n",
       "12321                     Network Analysis and Forensics   \n",
       "\n",
       "                 trainingprovideralias ihl_status  courseratings_stars  \\\n",
       "20277  SINGAPORE MANAGEMENT UNIVERSITY        IHL                  0.0   \n",
       "12321            Singapore Polytechnic        IHL                  0.0   \n",
       "\n",
       "       jobcareer_impact_stars  full_course_fee  course_fee_after_subsidies  \\\n",
       "20277                     0.0           3000.0                       900.0   \n",
       "12321                     0.0           1824.0                      1824.0   \n",
       "\n",
       "       number_of_hours training_commitment  \\\n",
       "20277             22.0           Full Time   \n",
       "12321             60.0           Part Time   \n",
       "\n",
       "                                       about_this_course  \\\n",
       "20277  Analysing the supply chain is of paramount imp...   \n",
       "12321  This course aims to equip diploma (and above) ...   \n",
       "\n",
       "                                          what_you_learn  attendancecount  \n",
       "20277  At the end of the 3-day module, participants w...              0.0  \n",
       "12321  The course introduces students with the fundam...              0.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/csv_training/training_course_directory.csv')\n",
    "df.sample(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db3f6bf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['coursetitle',\n",
       " 'trainingprovideralias',\n",
       " 'ihl_status',\n",
       " 'courseratings_stars',\n",
       " 'jobcareer_impact_stars',\n",
       " 'full_course_fee',\n",
       " 'course_fee_after_subsidies',\n",
       " 'number_of_hours',\n",
       " 'training_commitment',\n",
       " 'about_this_course',\n",
       " 'what_you_learn',\n",
       " 'attendancecount']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ae07a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Input Text:\n",
      "TITLE: Java Programming for Complete Beginners(Classroom and Synchronous e-learning). SCHOOL: NON-IHL. COURSE RATING: 4.0. JOB RATING: 0.0. FEE: $1400.0. FEE AFTER SUBSIDIES: $420.0. TRAINING HOUR: 28.0 hours. TRAINING COMMITMENT: Part Time. DESCRIPTIONS: LO1: Gather and confi rm the architecture requirements_x000D_LO2: Derive high-level design from specifi cation_x000D_LO3: Apply Java language syntax and layout_x000D_LO4: Apply basic object-oriented interaction principles_x000D_LO5: Document the design. SKILLS: Object-oriented design is a process by which a set of detailed object-oriented software design models are built, which are then used by the programmers to write and test programs for the new system. Systems design is the bridge between user requirements and programming the new system. One strength of the object-oriented approach is that the design models are often an extension of the requirements models. Object-oriented design is an analytical, rigorous, and detailed process and Java programming language is the selected programming language to implement such design into programs for the new system.\n",
      "Sample Target Value (Original): 12.0\n",
      "Sample Target Value (Scaled): [-0.17442319]\n"
     ]
    }
   ],
   "source": [
    "# Combine all descriptive columns (A-E) into a single text feature\n",
    "# This embeds the structured data (Rating, Fee, etc.) directly into the text for BERT\n",
    "df['Full_Text'] = (\n",
    "    \"TITLE: \" + df['coursetitle'].astype(str) + \". \" +\n",
    "    \"SCHOOL: \" + df['ihl_status'].astype(str) + \". \" +\n",
    "    \"COURSE RATING: \" + df['courseratings_stars'].astype(str) + \". \" +\n",
    "    \"JOB RATING: \" + df['jobcareer_impact_stars'].astype(str) + \". \" +\n",
    "    \"FEE: $\" + df['full_course_fee'].astype(str) + \". \" +\n",
    "    \"FEE AFTER SUBSIDIES: $\" + df['course_fee_after_subsidies'].astype(str) + \". \" +\n",
    "    \"TRAINING HOUR: \" + df['number_of_hours'].astype(str) + \" hours. \" +\n",
    "    \"TRAINING COMMITMENT: \" + df['training_commitment'].astype(str) + \". \" +\n",
    "    \"DESCRIPTIONS: \" + df['about_this_course'].astype(str) + \". \" +   \n",
    "    \"SKILLS: \" + df['what_you_learn'].astype(str)\n",
    ")\n",
    "\n",
    "X = df['Full_Text'].values\n",
    "y = df['attendancecount'].values\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Important: Scale the target variable (y) for better regression performance\n",
    "scaler = StandardScaler()\n",
    "y_train_scaled = scaler.fit_transform(y_train.reshape(-1, 1))\n",
    "y_test_scaled = scaler.transform(y_test.reshape(-1, 1))\n",
    "\n",
    "print(f\"Sample Input Text:\\n{X_train[0]}\")\n",
    "print(f\"Sample Target Value (Original): {y_train[0]}\")\n",
    "print(f\"Sample Target Value (Scaled): {y_train_scaled[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "63aea8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_5       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bert_text_classifi… │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>),     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BertTextClassifie…</span> │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>),      │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bert_backbone       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>),     │  <span style=\"color: #00af00; text-decoration-color: #00af00\">4,385,920</span> │ bert_text_classi… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BertBackbone</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)] │            │ bert_text_classi… │\n",
       "│                     │                   │            │ bert_text_classi… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_17          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bert_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dropout_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_5       │ (\u001b[38;5;45mNone\u001b[0m)            │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bert_text_classifi… │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m),     │          \u001b[38;5;34m0\u001b[0m │ input_layer_5[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mBertTextClassifie…\u001b[0m │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m),      │            │                   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bert_backbone       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m),     │  \u001b[38;5;34m4,385,920\u001b[0m │ bert_text_classi… │\n",
       "│ (\u001b[38;5;33mBertBackbone\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)] │            │ bert_text_classi… │\n",
       "│                     │                   │            │ bert_text_classi… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_17          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ bert_backbone[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │        \u001b[38;5;34m129\u001b[0m │ dropout_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,386,049</span> (16.73 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,386,049\u001b[0m (16.73 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,386,049</span> (16.73 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,386,049\u001b[0m (16.73 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def build_custom_bert_regression_model():\n",
    "    # Get the BERT Backbone and its Preprocessor\n",
    "    backbone = keras_nlp.models.BertBackbone.from_preset(\n",
    "        \"bert_tiny_en_uncased\",\n",
    "        load_weights=True,\n",
    "    )\n",
    "    \n",
    "    # Get the Preprocessor config (Crucial for tokenizing input)\n",
    "    preprocessor = keras_nlp.models.BertPreprocessor.from_preset(\n",
    "        \"bert_tiny_en_uncased\",\n",
    "        sequence_length=128\n",
    "    )\n",
    "\n",
    "    # Create the input layer and flow\n",
    "    # The preprocessor handles the [CLS], [SEP], padding, and tokenization.\n",
    "    inputs = tf.keras.Input(shape=(), dtype=tf.string)\n",
    "    \n",
    "    # Apply preprocessor to raw text input\n",
    "    x = preprocessor(inputs)\n",
    "    \n",
    "    # Pass tokenized data through the BERT backbone\n",
    "    # output_mask_index=0 ensures we get the hidden state of the [CLS] token\n",
    "    x = backbone(x)['pooled_output'] \n",
    "    \n",
    "    # Simple Regression Head\n",
    "    x = tf.keras.layers.Dropout(0.1)(x)\n",
    "    outputs = tf.keras.layers.Dense(1, activation='linear')(x) # Single linear output for regression\n",
    "\n",
    "    # Build the final model\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    \n",
    "    # Compile for Regression\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=3e-5),\n",
    "        loss=tf.keras.losses.MeanSquaredError(),\n",
    "        metrics=[tf.keras.metrics.MeanAbsoluteError(name='mae')]\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "regression_model = build_custom_bert_regression_model()\n",
    "print(\"\\nModel Summary:\")\n",
    "regression_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed523e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating token lengths...\n",
      "\n",
      "--- Token Length Analysis Summary ---\n",
      "BERT Preset Used: bert_tiny_en_uncased\n",
      "Max Sequence Length in Model: 64\n",
      "----------------------------------------\n",
      "Total Training Samples: 20650\n",
      "Average Token Length: 296.29 tokens\n",
      "Maximum Token Length: 1426 tokens\n",
      "Minimum Token Length: 66 tokens\n",
      "----------------------------------------\n",
      "Samples Exceeding 64 Tokens (Truncated): 20650 samples\n",
      "Percentage of Truncated Samples: 100.00%\n",
      "----------------------------------------\n",
      "Length of Longest Sample: 1426\n",
      "Length of Shortest Sample: 66\n"
     ]
    }
   ],
   "source": [
    "# --- Configuration ---\n",
    "PRESET = \"bert_tiny_en_uncased\"\n",
    "MAX_SEQUENCE_LENGTH = 128 # Your limit\n",
    "\n",
    "# --- 1. Load the Tokenizer ---\n",
    "# We use the raw tokenizer to see the length BEFORE padding/truncation\n",
    "tokenizer = keras_nlp.models.BertTokenizer.from_preset(\n",
    "    PRESET\n",
    ")\n",
    "\n",
    "# --- 2. Define a function to calculate token length ---\n",
    "# This function calculates the number of tokens for a given text,\n",
    "# *including* the automatically added [CLS] and [SEP] tokens.\n",
    "def get_token_length(text):\n",
    "    # Tokenize the text.\n",
    "    token_ids = tokenizer.tokenize(text)\n",
    "    # The length of the resulting tensor is the number of tokens\n",
    "    return tf.shape(token_ids)[0].numpy()\n",
    "\n",
    "# --- 3. Apply the function to your full dataset (X_train) ---\n",
    "print(\"Calculating token lengths...\")\n",
    "# Use list comprehension for efficient processing\n",
    "token_lengths = [get_token_length(text) for text in X_train]\n",
    "\n",
    "# Convert to a numpy array for easy statistical calculation\n",
    "token_lengths = np.array(token_lengths)\n",
    "\n",
    "# --- 4. Analyze Results ---\n",
    "\n",
    "# Calculate statistics\n",
    "avg_length = np.mean(token_lengths)\n",
    "max_length = np.max(token_lengths)\n",
    "min_length = np.min(token_lengths)\n",
    "\n",
    "# Calculate truncation metrics\n",
    "# An input is truncated if its length is greater than the MAX_SEQUENCE_LENGTH\n",
    "truncated_count = np.sum(token_lengths > MAX_SEQUENCE_LENGTH)\n",
    "total_samples = len(X_train)\n",
    "percent_truncated = (truncated_count / total_samples) * 100\n",
    "\n",
    "# --- 5. Print Summary ---\n",
    "print(\"\\n--- Token Length Analysis Summary ---\")\n",
    "print(f\"BERT Preset Used: {PRESET}\")\n",
    "print(f\"Max Sequence Length in Model: {MAX_SEQUENCE_LENGTH}\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"Total Training Samples: {total_samples}\")\n",
    "print(f\"Average Token Length: {avg_length:.2f} tokens\")\n",
    "print(f\"Maximum Token Length: {max_length} tokens\")\n",
    "print(f\"Minimum Token Length: {min_length} tokens\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"Samples Exceeding {MAX_SEQUENCE_LENGTH} Tokens (Truncated): {truncated_count} samples\")\n",
    "print(f\"Percentage of Truncated Samples: {percent_truncated:.2f}%\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Example of a long and short text's length\n",
    "long_sample_index = np.argmax(token_lengths)\n",
    "short_sample_index = np.argmin(token_lengths)\n",
    "\n",
    "print(f\"Length of Longest Sample: {token_lengths[long_sample_index]}\")\n",
    "print(f\"Length of Shortest Sample: {token_lengths[short_sample_index]}\")\n",
    "\n",
    "# Note: The calculation above includes the [CLS] and [SEP] tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a79431",
   "metadata": {},
   "source": [
    "<h3>Train BERT Model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d89064c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 11:05:46.566601: E tensorflow/core/util/util.cc:131] oneDNN supports DT_INT64 only on platforms with AVX-512. Falling back to the default Eigen-based implementation if present.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5163/5163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 48ms/step - loss: 1.0302 - mae: 0.4131 - val_loss: 0.7664 - val_mae: 0.2466\n",
      "Epoch 2/3\n",
      "\u001b[1m5163/5163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m251s\u001b[0m 49ms/step - loss: 0.9279 - mae: 0.3553 - val_loss: 0.7416 - val_mae: 0.2313\n",
      "Epoch 3/3\n",
      "\u001b[1m5163/5163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m251s\u001b[0m 49ms/step - loss: 0.8208 - mae: 0.3110 - val_loss: 0.7468 - val_mae: 0.2399\n",
      "Epoch 3: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 54ms/step\n",
      "\n",
      "--- Sample Predictions (Test Set) ---\n",
      "      Actual_Students  Predicted_Students\n",
      "0                 0.0               -73.0\n",
      "1                 0.0               -54.0\n",
      "2              1371.0               623.0\n",
      "3               436.0               205.0\n",
      "4                32.0                28.0\n",
      "...               ...                 ...\n",
      "5158             27.0                40.0\n",
      "5159              5.0               -30.0\n",
      "5160             22.0               159.0\n",
      "5161             13.0               -74.0\n",
      "5162              0.0               -43.0\n",
      "\n",
      "[5163 rows x 2 columns]\n",
      "\n",
      "Final Mean Absolute Error (Unscaled): 169.09 students\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_mae', \n",
    "    patience=1, \n",
    "    restore_best_weights=True,\n",
    "    verbose=1 \n",
    ")\n",
    "\n",
    "history = regression_model.fit(\n",
    "    x=X_train,\n",
    "    y=y_train_scaled,\n",
    "    validation_data=(X_test, y_test_scaled),\n",
    "    epochs=3,\n",
    "    batch_size=4, #change from 16 to 4 as WSL keep crashing during training\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Make predictions on the test set (results are scaled)\n",
    "y_pred_scaled = regression_model.predict(X_test)\n",
    "\n",
    "# Inverse transform the predictions to the original student count scale\n",
    "y_pred = scaler.inverse_transform(y_pred_scaled)\n",
    "\n",
    "# Display results\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual_Students': y_test,\n",
    "    'Predicted_Students': y_pred.flatten().round(0) # Round to nearest whole number\n",
    "})\n",
    "\n",
    "print(\"\\n--- Sample Predictions (Test Set) ---\")\n",
    "print(results_df)\n",
    "\n",
    "# Calculate final unscaled MAE\n",
    "final_mae = np.mean(np.abs(results_df['Actual_Students'] - results_df['Predicted_Students']))\n",
    "print(f\"\\nFinal Mean Absolute Error (Unscaled): {final_mae:.2f} students\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1cc7fa8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: 0.1736\n",
      "Mean Absolute Error (MAE): 169.0910\n",
      "Mean Squared Error (MSE): 396445.7933\n"
     ]
    }
   ],
   "source": [
    "# R2 Score (Coefficient of Determination)\n",
    "# Best value is 1.0. Can be negative.\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"R2 Score: {r2:.4f}\")\n",
    "\n",
    "# Mean Absolute Error (MAE)\n",
    "# Measures the average magnitude of the errors in a set of predictions.\n",
    "# Best value is 0.0.\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "\n",
    "# Mean Squared Error (MSE)\n",
    "# Measures the average of the squares of the errors. Penalizes larger errors more.\n",
    "# Best value is 0.0.\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error (MSE): {mse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df6637c",
   "metadata": {},
   "source": [
    "<h3>Save the model</h3>\n",
    "<p>Note: Save the model immediately as it take 30 - 60mins to train a model</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3c86bb36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model saved successfully to: data/model/bert_regression_model_vs2.keras\n"
     ]
    }
   ],
   "source": [
    "#Save the mode. Remember to change model name if needed\n",
    "MODEL_SAVE_PATH = 'data/model/bert_regression_model_vs2.keras'\n",
    "regression_model.save(MODEL_SAVE_PATH) \n",
    "print(f\"\\nModel saved successfully to: {MODEL_SAVE_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27903d59",
   "metadata": {},
   "source": [
    "<h3>Load the model (for testing)</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36b76921",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling BertTextClassifierPreprocessor.call().\n\n\u001b[1mCould not automatically infer the output shape / dtype of 'bert_text_classifier_preprocessor_5' (of type BertTextClassifierPreprocessor). Either the `BertTextClassifierPreprocessor.call()` method is incorrect, or you need to implement the `BertTextClassifierPreprocessor.compute_output_spec() / compute_output_shape()` method. Error encountered:\n\nException encountered when calling BertTokenizer.call().\n\n\u001b[1mNo vocabulary has been set for WordPieceTokenizer. Make sure to pass a `vocabulary` argument when creating the layer.\u001b[0m\n\nArguments received by BertTokenizer.call():\n  • inputs=tf.Tensor(shape=(None,), dtype=string)\n  • args=<class 'inspect._empty'>\n  • training=None\n  • kwargs=<class 'inspect._empty'>\u001b[0m\n\nArguments received by BertTextClassifierPreprocessor.call():\n  • args=('<KerasTensor shape=(None,), dtype=string, sparse=False, ragged=False, name=input_layer_5>',)\n  • kwargs=<class 'inspect._empty'>",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m model_path = \u001b[33m'\u001b[39m\u001b[33mdata/model/bert_regression_model_vs2.keras\u001b[39m\u001b[33m'\u001b[39m \n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m loaded_model = \u001b[43mkeras\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/bert_venv/lib/python3.12/site-packages/keras/src/saving/saving_api.py:189\u001b[39m, in \u001b[36mload_model\u001b[39m\u001b[34m(filepath, custom_objects, compile, safe_mode)\u001b[39m\n\u001b[32m    186\u001b[39m         is_keras_zip = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_keras_zip \u001b[38;5;129;01mor\u001b[39;00m is_keras_dir \u001b[38;5;129;01mor\u001b[39;00m is_hf:\n\u001b[32m--> \u001b[39m\u001b[32m189\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msaving_lib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    190\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m        \u001b[49m\u001b[43msafe_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43msafe_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath).endswith((\u001b[33m\"\u001b[39m\u001b[33m.h5\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m.hdf5\u001b[39m\u001b[33m\"\u001b[39m)):\n\u001b[32m    196\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m legacy_h5_format.load_model_from_hdf5(\n\u001b[32m    197\u001b[39m         filepath,\n\u001b[32m    198\u001b[39m         custom_objects=custom_objects,\n\u001b[32m    199\u001b[39m         \u001b[38;5;28mcompile\u001b[39m=\u001b[38;5;28mcompile\u001b[39m,\n\u001b[32m    200\u001b[39m         safe_mode=safe_mode,\n\u001b[32m    201\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/bert_venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:365\u001b[39m, in \u001b[36mload_model\u001b[39m\u001b[34m(filepath, custom_objects, compile, safe_mode)\u001b[39m\n\u001b[32m    360\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    361\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mInvalid filename: expected a `.keras` extension. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    362\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mReceived: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    363\u001b[39m     )\n\u001b[32m    364\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filepath, \u001b[33m\"\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m--> \u001b[39m\u001b[32m365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load_model_from_fileobj\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    366\u001b[39m \u001b[43m        \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_mode\u001b[49m\n\u001b[32m    367\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/bert_venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:442\u001b[39m, in \u001b[36m_load_model_from_fileobj\u001b[39m\u001b[34m(fileobj, custom_objects, compile, safe_mode)\u001b[39m\n\u001b[32m    439\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m zf.open(_CONFIG_FILENAME, \u001b[33m\"\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    440\u001b[39m     config_json = f.read()\n\u001b[32m--> \u001b[39m\u001b[32m442\u001b[39m model = \u001b[43m_model_from_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    443\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig_json\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_mode\u001b[49m\n\u001b[32m    444\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    446\u001b[39m all_filenames = zf.namelist()\n\u001b[32m    447\u001b[39m extract_dir = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/bert_venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:431\u001b[39m, in \u001b[36m_model_from_config\u001b[39m\u001b[34m(config_json, custom_objects, compile, safe_mode)\u001b[39m\n\u001b[32m    429\u001b[39m \u001b[38;5;66;03m# Construct the model from the configuration file in the archive.\u001b[39;00m\n\u001b[32m    430\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m ObjectSharingScope():\n\u001b[32m--> \u001b[39m\u001b[32m431\u001b[39m     model = \u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    432\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43msafe_mode\u001b[49m\n\u001b[32m    433\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    434\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/bert_venv/lib/python3.12/site-packages/keras/src/saving/serialization_lib.py:733\u001b[39m, in \u001b[36mdeserialize_keras_object\u001b[39m\u001b[34m(config, custom_objects, safe_mode, **kwargs)\u001b[39m\n\u001b[32m    731\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m custom_obj_scope, safe_mode_scope:\n\u001b[32m    732\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m         instance = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfrom_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43minner_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    734\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    735\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    736\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m could not be deserialized properly. Please\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    737\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m ensure that components that are Python object\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    741\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mconfig=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mException encountered: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    742\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/bert_venv/lib/python3.12/site-packages/keras/src/models/model.py:694\u001b[39m, in \u001b[36mModel.from_config\u001b[39m\u001b[34m(cls, config, custom_objects)\u001b[39m\n\u001b[32m    689\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_functional_config \u001b[38;5;129;01mand\u001b[39;00m revivable_as_functional:\n\u001b[32m    690\u001b[39m     \u001b[38;5;66;03m# Revive Functional model\u001b[39;00m\n\u001b[32m    691\u001b[39m     \u001b[38;5;66;03m# (but not Functional subclasses with a custom __init__)\u001b[39;00m\n\u001b[32m    692\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m functional_from_config\n\u001b[32m--> \u001b[39m\u001b[32m694\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunctional_from_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    695\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_objects\u001b[49m\n\u001b[32m    696\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    698\u001b[39m \u001b[38;5;66;03m# Either the model has a custom __init__, or the config\u001b[39;00m\n\u001b[32m    699\u001b[39m \u001b[38;5;66;03m# does not contain all the information necessary to\u001b[39;00m\n\u001b[32m    700\u001b[39m \u001b[38;5;66;03m# revive a Functional model. This happens when the user creates\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    703\u001b[39m \u001b[38;5;66;03m# In this case, we fall back to provide all config into the\u001b[39;00m\n\u001b[32m    704\u001b[39m \u001b[38;5;66;03m# constructor of the class.\u001b[39;00m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/bert_venv/lib/python3.12/site-packages/keras/src/models/functional.py:577\u001b[39m, in \u001b[36mfunctional_from_config\u001b[39m\u001b[34m(cls, config, custom_objects)\u001b[39m\n\u001b[32m    575\u001b[39m node_data = node_data_list[node_index]\n\u001b[32m    576\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m577\u001b[39m     \u001b[43mprocess_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    579\u001b[39m \u001b[38;5;66;03m# If the node does not have all inbound layers\u001b[39;00m\n\u001b[32m    580\u001b[39m \u001b[38;5;66;03m# available, stop processing and continue later\u001b[39;00m\n\u001b[32m    581\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/bert_venv/lib/python3.12/site-packages/keras/src/models/functional.py:507\u001b[39m, in \u001b[36mfunctional_from_config.<locals>.process_node\u001b[39m\u001b[34m(layer, node_data)\u001b[39m\n\u001b[32m    504\u001b[39m args, kwargs = deserialize_node(node_data, created_layers)\n\u001b[32m    505\u001b[39m \u001b[38;5;66;03m# Call layer on its inputs, thus creating the node\u001b[39;00m\n\u001b[32m    506\u001b[39m \u001b[38;5;66;03m# and building the layer if needed.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m507\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/bert_venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/bert_venv/lib/python3.12/site-packages/keras_hub/src/utils/tensor_utils.py:83\u001b[39m, in \u001b[36mpreprocessing_function.<locals>.wrapper\u001b[39m\u001b[34m(self, x, y, sample_weight, **kwargs)\u001b[39m\n\u001b[32m     79\u001b[39m x, y, sample_weight = convert_preprocessing_inputs(\n\u001b[32m     80\u001b[39m     (x, y, sample_weight)\n\u001b[32m     81\u001b[39m )\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m no_convert_scope():\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m     x = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m convert_preprocessing_outputs(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/bert_venv/lib/python3.12/site-packages/keras_hub/src/models/text_classifier_preprocessor.py:97\u001b[39m, in \u001b[36mTextClassifierPreprocessor.call\u001b[39m\u001b[34m(self, x, y, sample_weight)\u001b[39m\n\u001b[32m     94\u001b[39m \u001b[38;5;129m@preprocessing_function\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, y=\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m     96\u001b[39m     x = x \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m (x,)\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m     x = \u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43msegment\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msegment\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     98\u001b[39m     token_ids, segment_ids = \u001b[38;5;28mself\u001b[39m.packer(x)\n\u001b[32m     99\u001b[39m     x = {\n\u001b[32m    100\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtoken_ids\u001b[39m\u001b[33m\"\u001b[39m: token_ids,\n\u001b[32m    101\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mpadding_mask\u001b[39m\u001b[33m\"\u001b[39m: token_ids != \u001b[38;5;28mself\u001b[39m.tokenizer.pad_token_id,\n\u001b[32m    102\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33msegment_ids\u001b[39m\u001b[33m\"\u001b[39m: segment_ids,\n\u001b[32m    103\u001b[39m     }\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/bert_venv/lib/python3.12/site-packages/keras_hub/src/models/text_classifier_preprocessor.py:97\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     94\u001b[39m \u001b[38;5;129m@preprocessing_function\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, y=\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m     96\u001b[39m     x = x \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m (x,)\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m     x = \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43msegment\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m segment \u001b[38;5;129;01min\u001b[39;00m x)\n\u001b[32m     98\u001b[39m     token_ids, segment_ids = \u001b[38;5;28mself\u001b[39m.packer(x)\n\u001b[32m     99\u001b[39m     x = {\n\u001b[32m    100\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtoken_ids\u001b[39m\u001b[33m\"\u001b[39m: token_ids,\n\u001b[32m    101\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mpadding_mask\u001b[39m\u001b[33m\"\u001b[39m: token_ids != \u001b[38;5;28mself\u001b[39m.tokenizer.pad_token_id,\n\u001b[32m    102\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33msegment_ids\u001b[39m\u001b[33m\"\u001b[39m: segment_ids,\n\u001b[32m    103\u001b[39m     }\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/bert_venv/lib/python3.12/site-packages/keras_hub/src/utils/tensor_utils.py:71\u001b[39m, in \u001b[36mpreprocessing_function.<locals>.wrapper\u001b[39m\u001b[34m(self, x, **kwargs)\u001b[39m\n\u001b[32m     69\u001b[39m x = convert_preprocessing_inputs(x)\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m no_convert_scope():\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m     x = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m convert_preprocessing_outputs(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/bert_venv/lib/python3.12/site-packages/keras_hub/src/tokenizers/tokenizer.py:197\u001b[39m, in \u001b[36mTokenizer.call\u001b[39m\u001b[34m(self, inputs, training, *args, **kwargs)\u001b[39m\n\u001b[32m    195\u001b[39m \u001b[38;5;129m@preprocessing_function\u001b[39m\n\u001b[32m    196\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, *args, training=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m197\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/bert_venv/lib/python3.12/site-packages/keras_hub/src/utils/tensor_utils.py:71\u001b[39m, in \u001b[36mpreprocessing_function.<locals>.wrapper\u001b[39m\u001b[34m(self, x, **kwargs)\u001b[39m\n\u001b[32m     69\u001b[39m x = convert_preprocessing_inputs(x)\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m no_convert_scope():\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m     x = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m convert_preprocessing_outputs(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/bert_venv/lib/python3.12/site-packages/keras_hub/src/tokenizers/word_piece_tokenizer.py:461\u001b[39m, in \u001b[36mWordPieceTokenizer.tokenize\u001b[39m\u001b[34m(self, inputs)\u001b[39m\n\u001b[32m    459\u001b[39m \u001b[38;5;129m@preprocessing_function\u001b[39m\n\u001b[32m    460\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtokenize\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs):\n\u001b[32m--> \u001b[39m\u001b[32m461\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_check_vocabulary\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    462\u001b[39m     inputs = tf.convert_to_tensor(inputs)\n\u001b[32m    463\u001b[39m     unbatched = inputs.shape.rank == \u001b[32m0\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/bert_venv/lib/python3.12/site-packages/keras_hub/src/tokenizers/word_piece_tokenizer.py:454\u001b[39m, in \u001b[36mWordPieceTokenizer._check_vocabulary\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    452\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_check_vocabulary\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    453\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.vocabulary \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m454\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    455\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mNo vocabulary has been set for WordPieceTokenizer. Make sure \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    456\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mto pass a `vocabulary` argument when creating the layer.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    457\u001b[39m         )\n",
      "\u001b[31mValueError\u001b[39m: Exception encountered when calling BertTextClassifierPreprocessor.call().\n\n\u001b[1mCould not automatically infer the output shape / dtype of 'bert_text_classifier_preprocessor_5' (of type BertTextClassifierPreprocessor). Either the `BertTextClassifierPreprocessor.call()` method is incorrect, or you need to implement the `BertTextClassifierPreprocessor.compute_output_spec() / compute_output_shape()` method. Error encountered:\n\nException encountered when calling BertTokenizer.call().\n\n\u001b[1mNo vocabulary has been set for WordPieceTokenizer. Make sure to pass a `vocabulary` argument when creating the layer.\u001b[0m\n\nArguments received by BertTokenizer.call():\n  • inputs=tf.Tensor(shape=(None,), dtype=string)\n  • args=<class 'inspect._empty'>\n  • training=None\n  • kwargs=<class 'inspect._empty'>\u001b[0m\n\nArguments received by BertTextClassifierPreprocessor.call():\n  • args=('<KerasTensor shape=(None,), dtype=string, sparse=False, ragged=False, name=input_layer_5>',)\n  • kwargs=<class 'inspect._empty'>"
     ]
    }
   ],
   "source": [
    "model_path = 'data/model/bert_regression_model_vs2.keras' \n",
    "loaded_model = keras.models.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02504820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461ms/step\n",
      "\n",
      "--- NEW COURSE PREDICTION ---\n",
      "Predicted Number of Students to Attend: **113**\n"
     ]
    }
   ],
   "source": [
    "def predict_new_course_students(model, scaler, course_data):\n",
    "    #Remeber to change the key to new one after testing the first model\n",
    "    new_input_text = (\n",
    "        \"TITLE: \" + str(course_data['coursetitle']) + \". \" +\n",
    "        \"SCHOOL: \" + str(course_data['ihl_status']) + \". \" +\n",
    "        \"COURSE RATING: \" + str(course_data['courseratings_stars']) + \". \" +\n",
    "        \"JOB RATING: \" + str(course_data['jobcareer_impact_stars']) + \". \" +\n",
    "        \"FEE: $\" + str(course_data['full_course_fee']) + \". \" +\n",
    "        \"FEE AFTER SUBSIDIES: $\" + str(course_data['course_fee_after_subsidies']) + \". \" +\n",
    "        \"TRAINING HOUR: \" + str(course_data['number_of_hours']) + \" hours. \" +\n",
    "        \"TRAINING COMMITMENT: \" + str(course_data['training_commitment']) + \". \" +\n",
    "        \"DESCRIPTIONS: \" + str(course_data['about_this_course']) + \". \" + \n",
    "        \"SKILLS: \" + str(course_data['what_you_learn'])\n",
    "    )\n",
    "\n",
    "    # Convert the single string into a NumPy array of strings for the model\n",
    "    X_new = np.array([new_input_text])\n",
    "    \n",
    "    # --- B. Run Prediction ---\n",
    "    # Model predicts the scaled student count\n",
    "    y_pred_scaled = model.predict(X_new)\n",
    "    \n",
    "    # --- C. Inverse Transform and Finalize ---\n",
    "    # Convert scaled value back to original student count\n",
    "    y_pred = scaler.inverse_transform(y_pred_scaled)\n",
    "    \n",
    "    # Round to the nearest whole number and ensure it's not negative\n",
    "    predicted_students = max(0, int(round(y_pred[0][0])))\n",
    "    \n",
    "    return predicted_students, new_input_text\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "## 🎯 Define the New Course Data\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Define the features for a hypothetical new course\n",
    "new_course_features = {\n",
    "    'coursetitle': \"Engineering Ethics\",\n",
    "    'ihl_status': \"IHL\",\n",
    "    'courseratings_stars': 4.0,\n",
    "    'jobcareer_impact_stars': 4.0,\n",
    "    'full_course_fee': 1461.0,\n",
    "    'course_fee_after_subsidies': 438.30,\n",
    "    'number_of_hours': 36,\n",
    "    'training_commitment': \"Full-time\",\n",
    "    'about_this_course': \"Refer to website\",\n",
    "    'what_you_learn': \"Refer to website\"\n",
    "    #'about_this_course': \"Nowadays, technology has a pervasive and profound impact on everyday life, where engineers play a crucial role in its development. It is therefore extremely important that engineers understand the importance of safety, health, and welfare of the public, when developing this technology. They must be morally committed and equipped to tackle any ethical issues they may encounter. This course aims at training the student to reach such a status through discussions and typical case studies where real examples are thoroughly discussed.\",\n",
    "    #'what_you_learn': \"Ethics and Professionalism. Moral Choices and Ethical Dilemmas. Codes of Ethics. Moral Frameworks. Ethics as Social Experimentation. Safety and Risk. Assessing and Reducing Risk. Workplace Responsibilities and Rights. Truth and Truthfulness. Computer Ethics. Environmental Ethics;\"\n",
    "}\n",
    "\n",
    "# --- Execute the Prediction ---\n",
    "if regression_model:\n",
    "    predicted_count, input_text = predict_new_course_students(loaded_model, scaler, new_course_features)\n",
    "\n",
    "    print(\"\\n--- NEW COURSE PREDICTION ---\")\n",
    "    print(f\"Predicted Number of Students to Attend: **{predicted_count}**\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bert_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
